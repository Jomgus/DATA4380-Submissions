{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66421224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source llm_fine_tuning_venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e396eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jomus/Code/summer/lora_project/mlx-examples/lora\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/jomus/Code/summer/lora_project/mlx-examples/lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3666aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jomus/Code/summer/lora_project/llm_fine_tuning_venv/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Preparing 1000 samples for training...\n",
      "Preparing 100 samples for testing...\n",
      "Summarization data successfully saved to the 'summarization_data' directory.\n"
     ]
    }
   ],
   "source": [
    "!python prepare_summarization_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9e6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ./phi3_quantized...\n",
      "Loading benchmark data from summarization_data/test.jsonl...\n",
      "Running inference on 100 samples...\n",
      "Benchmarking: 100%|███████████████████████████| 100/100 [16:58<00:00, 10.18s/it]\n",
      "Results saved to baseline_summarization_results.jsonl\n",
      "Calculating ROUGE score...\n",
      "\n",
      "--- Baseline Summarization Benchmark Results ---\n",
      "ROUGE-1 Score: 0.1737\n",
      "ROUGE-L Score: 0.1255\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python run_summarization_benchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a2962",
   "metadata": {},
   "source": [
    "# Project Prototype: Teaching an AI on my Mac\n",
    "This project is a working prototype that shows how to teach (fine-tune) a powerful AI model (Phi-3-mini) a new skill right on my MacBook.\n",
    "\n",
    "## What This Prototype Does:\n",
    "\n",
    "The goal is to teach the AI how to get better at summarizing news articles. The prototype successfully completes these key steps:\n",
    "\n",
    "Prepares the Model: It takes the big Phi-3 model and makes a smaller, more efficient version that can be trained on my Mac.\n",
    "\n",
    "Prepares the Data: It creates a \"study guide\" (1,000 news articles and their summaries) for the AI to learn from and a \"final exam\" (100 different articles) to test it.\n",
    "\n",
    "Gets a \"Before\" Score: It gives the \"final exam\" to the original model to see how well it does before any training.\n",
    "\n",
    "I'm using a metric called ROUGE. ROUGE works by comparing the words in the AI's summary to the words in the correct, human-written summary. A higher score means the AI did a better job of capturing the key points.\n",
    "\n",
    "## What This Proves:\n",
    "\n",
    "This prototype proves that my entire process works from start to finish. I now have a reliable system ready to do the final step: train the model and see if we can improve its score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4ab1d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_fine_tuning_venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
